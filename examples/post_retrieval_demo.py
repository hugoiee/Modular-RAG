"""
æ£€ç´¢åæ¨¡å—ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ PostRetrievalModule çš„å„ç§ä¼˜åŒ–ç­–ç•¥
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from nodes.indexing import IndexModule
from nodes.retrieval import RetrievalModule
from nodes.post_retrieval import PostRetrievalModule, PostRetrievalPipeline

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def setup_test_data():
    """å‡†å¤‡æµ‹è¯•æ•°æ®"""
    print("\n" + "=" * 70)
    print("å‡†å¤‡æµ‹è¯•æ•°æ®")
    print("=" * 70)

    # ç´¢å¼•æ–‡æ¡£
    index_config = {
        "loader": {"type": "directory", "file_extensions": [".pdf"]},
        "splitter": {"type": "recursive", "chunk_size": 1000, "chunk_overlap": 200},
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/post_retrieval_demo_db",
            "collection_name": "post_retrieval_test"
        },
    }

    index_module = IndexModule(index_config)
    vectorstore = index_module.index_documents("./doc/é‡‘èæ–°é—»pdf/", verbose=False)

    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ")

    return vectorstore


def example_1_rerank(vectorstore):
    """ç¤ºä¾‹ 1: åŸºç¡€é‡æ’åº"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 1: Rerankï¼ˆåŸºç¡€é‡æ’åºï¼‰")
    print("=" * 70)

    # å…ˆæ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 10})
    retrieval.build(vectorstore=vectorstore)
    query = "ç¾å›½ç§‘æŠ€å…¬å¸çš„è£å‘˜æƒ…å†µ"
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\næ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
    print("\né‡æ’åºå‰ï¼ˆå‰3ä¸ªï¼‰:")
    for i, doc in enumerate(docs[:3], 1):
        print(f"{i}. {doc.page_content[:80]}...")

    # é‡æ’åº
    post_retrieval = PostRetrievalModule({"strategy": "rerank", "top_n": 5})
    reranked = post_retrieval.process(docs, query, verbose=False)

    print(f"\né‡æ’åºåï¼ˆå‰3ä¸ªï¼‰:")
    for i, doc in enumerate(reranked[:3], 1):
        print(f"{i}. {doc.page_content[:80]}...")


def example_2_diversity_rerank(vectorstore):
    """ç¤ºä¾‹ 2: å¤šæ ·æ€§é‡æ’åº"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 2: Diversity Rerankï¼ˆå¤šæ ·æ€§é‡æ’åºï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 10})
    retrieval.build(vectorstore=vectorstore)
    query = "ç§‘æŠ€è¡Œä¸šæŠ•èµ„é£é™©"
    docs = retrieval.retrieve(query, verbose=False)

    # å¤šæ ·æ€§é‡æ’åº
    config = {
        "strategy": "diversity_rerank",
        "diversity_weight": 0.6,
        "top_n": 5
    }
    post_retrieval = PostRetrievalModule(config)
    reranked = post_retrieval.process(docs, query, verbose=False)

    print(f"\nå¤šæ ·æ€§é‡æ’åºç»“æœï¼ˆ{len(reranked)} ä¸ªæ–‡æ¡£ï¼‰:")
    for i, doc in enumerate(reranked, 1):
        print(f"{i}. {doc.page_content[:80]}...")


def example_3_llm_rerank(vectorstore):
    """ç¤ºä¾‹ 3: LLM é‡æ’åº"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 3: LLM Rerankï¼ˆä½¿ç”¨ LLM è¯„åˆ†é‡æ’åºï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 5})
    retrieval.build(vectorstore=vectorstore)
    query = "äººå·¥æ™ºèƒ½æŠ•èµ„çš„ä¸»è¦é£é™©æ˜¯ä»€ä¹ˆï¼Ÿ"
    docs = retrieval.retrieve(query, verbose=False)

    # LLM é‡æ’åº
    config = {
        "strategy": "llm_rerank",
        "model": "qwen-plus",
        "top_n": 3
    }
    post_retrieval = PostRetrievalModule(config)
    reranked = post_retrieval.process(docs, query, verbose=False)

    print(f"\nLLM é‡æ’åºç»“æœï¼ˆ{len(reranked)} ä¸ªæ–‡æ¡£ï¼‰:")
    for i, doc in enumerate(reranked, 1):
        print(f"{i}. {doc.page_content[:100]}...")


def example_4_context_compression(vectorstore):
    """ç¤ºä¾‹ 4: ä¸Šä¸‹æ–‡å‹ç¼©"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 4: Context Compressionï¼ˆä¸Šä¸‹æ–‡å‹ç¼©ï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 5})
    retrieval.build(vectorstore=vectorstore)
    query = "è£å‘˜åŸå› "
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\nå‹ç¼©å‰:")
    for i, doc in enumerate(docs[:2], 1):
        print(f"æ–‡æ¡£ {i} é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
        print(f"å†…å®¹: {doc.page_content[:150]}...\n")

    # å‹ç¼©
    config = {
        "strategy": "context_compression",
        "compression_ratio": 0.5,
        "max_tokens": 200
    }
    post_retrieval = PostRetrievalModule(config)
    compressed = post_retrieval.process(docs, query, verbose=False)

    print(f"\nå‹ç¼©å:")
    for i, doc in enumerate(compressed[:2], 1):
        print(f"æ–‡æ¡£ {i} é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
        print(f"å†…å®¹: {doc.page_content[:150]}...\n")


def example_5_summary_compression(vectorstore):
    """ç¤ºä¾‹ 5: æ‘˜è¦å‹ç¼©"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 5: Summary Compressionï¼ˆæ‘˜è¦å‹ç¼©ï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 3})
    retrieval.build(vectorstore=vectorstore)
    query = "ç§‘æŠ€è‚¡æ³¡æ²«"
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\nåŸå§‹æ–‡æ¡£ï¼ˆç¬¬1ä¸ªï¼‰:")
    print(f"é•¿åº¦: {len(docs[0].page_content)} å­—ç¬¦")
    print(f"å†…å®¹: {docs[0].page_content[:200]}...")

    # æ‘˜è¦å‹ç¼©
    config = {
        "strategy": "summary_compression",
        "model": "qwen-plus",
        "max_summary_length": 150
    }
    post_retrieval = PostRetrievalModule(config)
    summarized = post_retrieval.process(docs, query, verbose=False)

    print(f"\næ‘˜è¦åï¼ˆç¬¬1ä¸ªï¼‰:")
    print(f"é•¿åº¦: {len(summarized[0].page_content)} å­—ç¬¦")
    print(f"æ‘˜è¦: {summarized[0].page_content}")


def example_6_relevance_filter(vectorstore):
    """ç¤ºä¾‹ 6: ç›¸å…³æ€§è¿‡æ»¤"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 6: Relevance Filterï¼ˆç›¸å…³æ€§è¿‡æ»¤ï¼‰")
    print("=" * 70)

    # æ£€ç´¢ï¼ˆè·å–æ›´å¤šæ–‡æ¡£ï¼Œå…¶ä¸­å¯èƒ½æœ‰ä¸ç›¸å…³çš„ï¼‰
    retrieval = RetrievalModule({"strategy": "dense", "k": 8})
    retrieval.build(vectorstore=vectorstore)
    query = "è‹±ç‰¹å°”å…¬å¸çš„è£å‘˜æ•°é‡"
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\nè¿‡æ»¤å‰: {len(docs)} ä¸ªæ–‡æ¡£")

    # ç›¸å…³æ€§è¿‡æ»¤
    config = {
        "strategy": "relevance_filter",
        "model": "qwen-plus",
        "relevance_threshold": 0.5,
        "min_docs": 2
    }
    post_retrieval = PostRetrievalModule(config)
    filtered = post_retrieval.process(docs, query, verbose=False)

    print(f"\nè¿‡æ»¤å: {len(filtered)} ä¸ªç›¸å…³æ–‡æ¡£")


def example_7_redundancy_filter(vectorstore):
    """ç¤ºä¾‹ 7: å†—ä½™è¿‡æ»¤"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 7: Redundancy Filterï¼ˆå†—ä½™è¿‡æ»¤ï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 10})
    retrieval.build(vectorstore=vectorstore)
    query = "ç§‘æŠ€å…¬å¸è£å‘˜"
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\nå»é‡å‰: {len(docs)} ä¸ªæ–‡æ¡£")

    # å†—ä½™è¿‡æ»¤
    config = {
        "strategy": "redundancy_filter",
        "similarity_threshold": 0.8
    }
    post_retrieval = PostRetrievalModule(config)
    filtered = post_retrieval.process(docs, query, verbose=False)

    print(f"\nå»é‡å: {len(filtered)} ä¸ªå”¯ä¸€æ–‡æ¡£")


def example_8_pipeline(vectorstore):
    """ç¤ºä¾‹ 8: æ£€ç´¢åæµæ°´çº¿"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 8: Post-Retrieval Pipelineï¼ˆå¤šæ­¥éª¤ä¼˜åŒ–ï¼‰")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 15})
    retrieval.build(vectorstore=vectorstore)
    query = "ç¾å›½ç§‘æŠ€è¡Œä¸šçš„ä¸»è¦é—®é¢˜"
    docs = retrieval.retrieve(query, verbose=False)

    print(f"\nåŸå§‹æ£€ç´¢ç»“æœ: {len(docs)} ä¸ªæ–‡æ¡£")

    # åˆ›å»ºæµæ°´çº¿
    pipeline = PostRetrievalPipeline()
    pipeline.add_step("rerank", {"top_n": 10})               # æ­¥éª¤1: é‡æ’åº
    pipeline.add_step("redundancy_filter", {"similarity_threshold": 0.85})  # æ­¥éª¤2: å»é‡
    pipeline.add_step("context_compression", {"compression_ratio": 0.6})    # æ­¥éª¤3: å‹ç¼©

    # æ‰§è¡Œæµæ°´çº¿
    optimized = pipeline.process(docs, query, verbose=True)

    print(f"\næœ€ç»ˆç»“æœï¼ˆå‰2ä¸ªï¼‰:")
    for i, doc in enumerate(optimized[:2], 1):
        print(f"\næ–‡æ¡£ {i}:")
        print(f"é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
        print(f"å†…å®¹: {doc.page_content[:150]}...")


def example_9_dynamic_strategy(vectorstore):
    """ç¤ºä¾‹ 9: åŠ¨æ€åˆ‡æ¢ç­–ç•¥"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 9: åŠ¨æ€åˆ‡æ¢ä¼˜åŒ–ç­–ç•¥")
    print("=" * 70)

    # æ£€ç´¢
    retrieval = RetrievalModule({"strategy": "dense", "k": 8})
    retrieval.build(vectorstore=vectorstore)
    query = "æŠ•èµ„é£é™©"
    docs = retrieval.retrieve(query, verbose=False)

    # åˆ›å»ºæ¨¡å—ï¼Œåˆå§‹ä½¿ç”¨ Rerank
    post_retrieval = PostRetrievalModule({"strategy": "rerank", "top_n": 5})

    print(f"\nåŸå§‹æ–‡æ¡£: {len(docs)} ä¸ª")

    # ç­–ç•¥ 1: Rerank
    print("\n--- ç­–ç•¥ 1: Rerank ---")
    result1 = post_retrieval.process(docs, query, verbose=False)
    print(f"ç»“æœ: {len(result1)} ä¸ªæ–‡æ¡£")

    # åˆ‡æ¢åˆ°ç­–ç•¥ 2: Redundancy Filter
    print("\n--- åˆ‡æ¢ç­–ç•¥ ---")
    post_retrieval.change_strategy("redundancy_filter", {"similarity_threshold": 0.8})

    print("\n--- ç­–ç•¥ 2: Redundancy Filter ---")
    result2 = post_retrieval.process(docs, query, verbose=False)
    print(f"ç»“æœ: {len(result2)} ä¸ªæ–‡æ¡£")

    # åˆ‡æ¢åˆ°ç­–ç•¥ 3: Context Compression
    print("\n--- åˆ‡æ¢ç­–ç•¥ ---")
    post_retrieval.change_strategy("context_compression", {"compression_ratio": 0.5})

    print("\n--- ç­–ç•¥ 3: Context Compression ---")
    result3 = post_retrieval.process(docs, query, verbose=False)
    print(f"ç»“æœ: {len(result3)} ä¸ªæ–‡æ¡£ï¼ˆå·²å‹ç¼©ï¼‰")


def example_10_complete_workflow(vectorstore):
    """ç¤ºä¾‹ 10: å®Œæ•´å·¥ä½œæµï¼ˆæ£€ç´¢ + åå¤„ç†ï¼‰"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 10: å®Œæ•´å·¥ä½œæµï¼ˆRetrieval + Post-Retrievalï¼‰")
    print("=" * 70)

    query = "ç§‘æŠ€å…¬å¸å¤§è§„æ¨¡è£å‘˜çš„æ·±å±‚åŸå› "

    # æ­¥éª¤1: æ··åˆæ£€ç´¢
    print("\nğŸ“ æ­¥éª¤ 1: æ··åˆæ£€ç´¢")
    retrieval = RetrievalModule({
        "strategy": "hybrid",
        "dense_weight": 0.6,
        "sparse_weight": 0.4,
        "k": 10
    })
    # éœ€è¦ documents ç”¨äº BM25
    from nodes.indexing import IndexModule
    index_module = IndexModule()
    # å‡è®¾å·²æœ‰ vectorstore å’Œ documents
    # è¿™é‡Œç®€åŒ–ï¼Œåªç”¨ dense
    retrieval = RetrievalModule({"strategy": "dense", "k": 10})
    retrieval.build(vectorstore=vectorstore)

    docs = retrieval.retrieve(query, verbose=False)
    print(f"æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")

    # æ­¥éª¤2: åå¤„ç†æµæ°´çº¿
    print("\nğŸ“ æ­¥éª¤ 2: åå¤„ç†ä¼˜åŒ–")
    pipeline = PostRetrievalPipeline()
    pipeline.add_step("llm_rerank", {"top_n": 5})  # LLM é‡æ’åº
    pipeline.add_step("redundancy_filter")          # å»é‡
    pipeline.add_step("context_compression", {"compression_ratio": 0.7})  # å‹ç¼©

    optimized = pipeline.process(docs, query, verbose=False)

    print(f"\næœ€ç»ˆä¼˜åŒ–ç»“æœ: {len(optimized)} ä¸ªæ–‡æ¡£")
    print("\næœ€ç»ˆæ–‡æ¡£å†…å®¹ï¼ˆå‰2ä¸ªï¼‰:")
    for i, doc in enumerate(optimized[:2], 1):
        print(f"\næ–‡æ¡£ {i}:")
        print(f"é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
        print(f"å†…å®¹: {doc.page_content[:200]}...")


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ğŸš€ æ£€ç´¢åæ¨¡å—ç¤ºä¾‹æ¼”ç¤º")
    print("=" * 70)

    # å‡†å¤‡æ•°æ®
    vectorstore = setup_test_data()

    # è¿è¡Œç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šæƒ³è¦è¿è¡Œçš„ç¤ºä¾‹ï¼‰

    # é‡æ’åºç¤ºä¾‹
    example_1_rerank(vectorstore)
    # example_2_diversity_rerank(vectorstore)
    # example_3_llm_rerank(vectorstore)

    # å‹ç¼©ç¤ºä¾‹
    # example_4_context_compression(vectorstore)
    # example_5_summary_compression(vectorstore)

    # è¿‡æ»¤ç¤ºä¾‹
    # example_6_relevance_filter(vectorstore)
    # example_7_redundancy_filter(vectorstore)

    # æµæ°´çº¿å’Œå®Œæ•´å·¥ä½œæµ
    # example_8_pipeline(vectorstore)
    # example_9_dynamic_strategy(vectorstore)
    # example_10_complete_workflow(vectorstore)

    print("\n" + "=" * 70)
    print("âœ… ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 70)
    print("\nğŸ’¡ æç¤ºï¼šå¯ä»¥å–æ¶ˆæ³¨é‡Šå…¶ä»–ç¤ºä¾‹æ¥æµ‹è¯•æ›´å¤šåŠŸèƒ½")
