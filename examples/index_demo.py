"""
ç´¢å¼•æ¨¡å—ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ IndexModule çš„ä¸åŒé…ç½®å’Œç­–ç•¥
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from nodes.indexing import IndexModule

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def example_1_basic_indexing():
    """ç¤ºä¾‹ 1: åŸºç¡€ç´¢å¼•ï¼ˆé€’å½’åˆ†å— + Chromaï¼‰"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 1: åŸºç¡€ç´¢å¼•ï¼ˆé€’å½’åˆ†å—ï¼‰")
    print("=" * 70)

    config = {
        "loader": {"type": "web", "file_extensions": []},
        "splitter": {
            "type": "recursive",
            "chunk_size": 1000,
            "chunk_overlap": 200,
        },
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/chroma_basic",
            "collection_name": "basic_index"
        },
    }

    index_module = IndexModule(config)
    # vectorstore = index_module.index_documents("./doc/",False)
    vectorstore = index_module.index_documents("https://lilianweng.github.io/posts/2023-06-23-agent/", True)

    # æµ‹è¯•æ£€ç´¢
    retriever = index_module.get_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}
    )

    results = retriever.invoke("What is Agent")
    print(f"\nğŸ” æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
    for i, doc in enumerate(results, 1):
        print(f"\nç»“æœ {i}:")
        print(f"å†…å®¹: {doc.page_content[:300]}...")

    # æ‰“å°æ‘˜è¦
    print("\nğŸ“Š ç´¢å¼•æ‘˜è¦:")
    summary = index_module.summary()
    for key, value in summary.items():
        print(f"   {key}: {value}")


def example_2_small_to_big():
    """ç¤ºä¾‹ 2: Small-to-Big ç­–ç•¥"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 2: Small-to-Big ç´¢å¼•ç­–ç•¥")
    print("=" * 70)

    config = {
        "loader": {"type": "directory", "file_extensions": [".pdf"]},
        "splitter": {
            "type": "small_to_big",
            "small_chunk_size": 400,
            "small_chunk_overlap": 50,
            "big_chunk_size": 2000,
            "big_chunk_overlap": 200,
        },
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/chroma_small_to_big",
            "collection_name": "small_to_big_index"
        },
    }

    index_module = IndexModule(config)
    vectorstore = index_module.index_documents("./doc/é‡‘èæ–°é—»pdf/")

    # æµ‹è¯•æ£€ç´¢ï¼ˆæ£€ç´¢å°å—ï¼Œä½†å¯ä»¥è·å–çˆ¶å—ä¸Šä¸‹æ–‡ï¼‰
    retriever = index_module.get_retriever(search_kwargs={"k": 2})
    results = retriever.invoke("ç§‘æŠ€å…¬å¸è£å‘˜çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ")

    print(f"\nğŸ” æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
    for i, doc in enumerate(results, 1):
        print(f"\nç»“æœ {i}:")
        print(f"å°å—å†…å®¹: {doc.page_content[:100]}...")
        if "parent_chunk_content" in doc.metadata:
            print(f"çˆ¶å—å¤§å°: {doc.metadata['parent_chunk_size']} å­—ç¬¦")
            print(f"çˆ¶å—å†…å®¹é¢„è§ˆ: {doc.metadata['parent_chunk_content'][:150]}...")


def example_3_hierarchical():
    """ç¤ºä¾‹ 3: å±‚æ¬¡åŒ–ç´¢å¼•"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 3: å±‚æ¬¡åŒ–ç´¢å¼•ç­–ç•¥")
    print("=" * 70)

    config = {
        "loader": {"type": "directory", "file_extensions": [".pdf"]},
        "splitter": {
            "type": "recursive",  # å±‚æ¬¡åŒ–ç­–ç•¥ä¼šå¿½ç•¥è¿™ä¸ªè®¾ç½®
            "chunk_size": 1000,
        },
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/chroma_hierarchical",
            "collection_name": "hierarchical_index"
        },
        "strategy": {
            "type": "hierarchical",
        },
    }

    index_module = IndexModule(config)
    vectorstore = index_module.index_documents("./doc/é‡‘èæ–°é—»pdf/")

    # æµ‹è¯•æ£€ç´¢
    retriever = index_module.get_retriever(search_kwargs={"k": 3})
    results = retriever.invoke("è£å‘˜æ½®çš„èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ")

    print(f"\nğŸ” æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
    for i, doc in enumerate(results, 1):
        print(f"\nç»“æœ {i}:")
        print(f"å±‚çº§: Level {doc.metadata.get('level', 'N/A')}")
        print(f"èŠ‚ç‚¹ ID: {doc.metadata.get('node_id', 'N/A')}")
        print(f"å†…å®¹: {doc.page_content[:200]}...")


def example_4_semantic_splitter():
    """ç¤ºä¾‹ 4: è¯­ä¹‰åˆ†å—"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 4: è¯­ä¹‰åˆ†å—ç­–ç•¥")
    print("=" * 70)

    config = {
        "loader": {"type": "directory", "file_extensions": [".pdf"]},
        "splitter": {
            "type": "semantic",
            "chunk_size": 800,
            "chunk_overlap": 100,
        },
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/chroma_semantic",
            "collection_name": "semantic_index"
        },
    }

    index_module = IndexModule(config)
    vectorstore = index_module.index_documents("./doc/é‡‘èæ–°é—»pdf/")

    print("\nğŸ“Š ç´¢å¼•æ‘˜è¦:")
    summary = index_module.summary()
    for key, value in summary.items():
        print(f"   {key}: {value}")


def example_5_load_existing():
    """ç¤ºä¾‹ 5: åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•"""
    print("\n" + "=" * 70)
    print("ç¤ºä¾‹ 5: åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•")
    print("=" * 70)

    config = {
        "loader": {"type": "directory"},
        "splitter": {"type": "recursive"},
        "embedding": {"type": "dashscope", "model": "text-embedding-v4"},
        "store": {
            "type": "chroma",
            "persist_directory": "./data/chroma_basic",
            "collection_name": "basic_index"
        },
    }

    index_module = IndexModule(config)

    try:
        vectorstore = index_module.load_existing_index()

        # æµ‹è¯•æ£€ç´¢
        retriever = index_module.get_retriever(search_kwargs={"k": 2})
        results = retriever.invoke("ç§‘æŠ€è‚¡æ³¡æ²«")

        print(f"\nğŸ” æ£€ç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        for i, doc in enumerate(results, 1):
            print(f"\nç»“æœ {i}: {doc.page_content[:100]}...")

    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        print("æç¤º: è¯·å…ˆè¿è¡Œ example_1_basic_indexing() åˆ›å»ºç´¢å¼•")


if __name__ == "__main__":
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    os.makedirs("./data", exist_ok=True)

    # è¿è¡Œç¤ºä¾‹
    # æ³¨æ„ï¼šæ ¹æ®éœ€è¦å–æ¶ˆæ³¨é‡Šç›¸åº”çš„ç¤ºä¾‹

    # ç¤ºä¾‹ 1: åŸºç¡€ç´¢å¼•
    example_1_basic_indexing()

    # ç¤ºä¾‹ 2: Small-to-Big ç­–ç•¥
    # example_2_small_to_big()

    # ç¤ºä¾‹ 3: å±‚æ¬¡åŒ–ç´¢å¼•
    # example_3_hierarchical()

    # ç¤ºä¾‹ 4: è¯­ä¹‰åˆ†å—
    # example_4_semantic_splitter()

    # ç¤ºä¾‹ 5: åŠ è½½å·²å­˜åœ¨çš„ç´¢å¼•
    # example_5_load_existing()

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("=" * 70)
