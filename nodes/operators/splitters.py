"""
æ–‡æœ¬åˆ†å— Operators
å®ç°è®ºæ–‡ä¸­æåˆ°çš„å¤šç§åˆ†å—ä¼˜åŒ–ç­–ç•¥ï¼š
1. Sliding Windowï¼ˆæ»‘åŠ¨çª—å£ï¼‰
2. Metadata Attachmentï¼ˆå…ƒæ•°æ®é™„åŠ ï¼‰
3. Small-to-Bigï¼ˆå°åˆ°å¤§ç­–ç•¥ï¼‰
"""

from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_text_splitters import (
    RecursiveCharacterTextSplitter,
    CharacterTextSplitter,
)
from .base import BaseOperator


class SplitterOperator(BaseOperator):
    """æ–‡æœ¬åˆ†å—å™¨åŸºç±»"""

    def execute(self, documents: List[Document]) -> List[Document]:
        """
        å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œåˆ†å—

        Args:
            documents: Document å¯¹è±¡åˆ—è¡¨

        Returns:
            åˆ†å—åçš„ Document å¯¹è±¡åˆ—è¡¨
        """
        raise NotImplementedError


class RecursiveSplitterOperator(SplitterOperator):
    """
    é€’å½’å­—ç¬¦åˆ†å—å™¨
    å®ç°æ»‘åŠ¨çª—å£ï¼ˆSliding Windowï¼‰ç­–ç•¥
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.chunk_size = self.config.get("chunk_size", 1000)
        self.chunk_overlap = self.config.get("chunk_overlap", 200)  # æ»‘åŠ¨çª—å£é‡å 
        self.add_start_index = self.config.get("add_start_index", True)
        self.separators = self.config.get("separators", None)

    def execute(self, documents: List[Document]) -> List[Document]:
        """
        ä½¿ç”¨é€’å½’å­—ç¬¦åˆ†å‰²å™¨å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å—

        Args:
            documents: Document å¯¹è±¡åˆ—è¡¨

        Returns:
            åˆ†å—åçš„ Document å¯¹è±¡åˆ—è¡¨
        """
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            add_start_index=self.add_start_index,
            separators=self.separators,
        )

        splits = splitter.split_documents(documents)

        # å…ƒæ•°æ®å¢å¼ºï¼šæ·»åŠ åˆ†å—ä¿¡æ¯
        for i, split in enumerate(splits):
            split.metadata["chunk_id"] = i
            split.metadata["chunk_size"] = len(split.page_content)
            split.metadata["splitter_type"] = "recursive"

        return splits


class SemanticSplitterOperator(SplitterOperator):
    """
    è¯­ä¹‰åˆ†å—å™¨
    åŸºäºè¯­ä¹‰è¾¹ç•Œè¿›è¡Œåˆ†å—ï¼ˆæ®µè½ã€å¥å­ï¼‰
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.chunk_size = self.config.get("chunk_size", 1000)
        self.chunk_overlap = self.config.get("chunk_overlap", 100)
        # ä½¿ç”¨æ®µè½å’Œå¥å­ä½œä¸ºåˆ†éš”ç¬¦
        self.separators = ["\n\n", "\n", "ã€‚", "!", "?", ";", "ï¼›", ":", "ï¼š"]

    def execute(self, documents: List[Document]) -> List[Document]:
        """
        åŸºäºè¯­ä¹‰è¾¹ç•Œè¿›è¡Œåˆ†å—

        Args:
            documents: Document å¯¹è±¡åˆ—è¡¨

        Returns:
            åˆ†å—åçš„ Document å¯¹è±¡åˆ—è¡¨
        """
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            add_start_index=True,
            separators=self.separators,
        )

        splits = splitter.split_documents(documents)

        # å…ƒæ•°æ®å¢å¼º
        for i, split in enumerate(splits):
            split.metadata["chunk_id"] = i
            split.metadata["chunk_size"] = len(split.page_content)
            split.metadata["splitter_type"] = "semantic"

        return splits


class SmallToBigSplitterOperator(SplitterOperator):
    """
    Small-to-Big åˆ†å—ç­–ç•¥ï¼ˆè®ºæ–‡æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ï¼‰

    æ ¸å¿ƒæ€æƒ³ï¼š
    1. åˆ›å»ºå°å—ç”¨äºæ£€ç´¢ï¼ˆæé«˜æ£€ç´¢ç²¾åº¦ï¼‰
    2. ä¿ç•™å¤§å—ï¼ˆçˆ¶å—ï¼‰ç”¨äºä¸Šä¸‹æ–‡ç”Ÿæˆ
    3. æ£€ç´¢æ—¶ä½¿ç”¨å°å—ï¼Œç”Ÿæˆæ—¶å¼•ç”¨å¯¹åº”çš„å¤§å—

    å®ç°æ–¹å¼ï¼š
    - å°å—ï¼šç”¨äºå‘é‡åŒ–å’Œæ£€ç´¢
    - å¤§å—ï¼šä½œä¸ºçˆ¶æ–‡æ¡£ï¼Œæä¾›å®Œæ•´ä¸Šä¸‹æ–‡
    - é€šè¿‡ metadata ç»´æŠ¤çˆ¶å­å…³ç³»
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        # å°å—é…ç½®ï¼ˆç”¨äºæ£€ç´¢ï¼‰
        self.small_chunk_size = self.config.get("small_chunk_size", 400)
        self.small_chunk_overlap = self.config.get("small_chunk_overlap", 50)

        # å¤§å—é…ç½®ï¼ˆç”¨äºç”Ÿæˆï¼‰
        self.big_chunk_size = self.config.get("big_chunk_size", 2000)
        self.big_chunk_overlap = self.config.get("big_chunk_overlap", 200)

    def execute(self, documents: List[Document]) -> List[Document]:
        """
        æ‰§è¡Œ Small-to-Big åˆ†å—ç­–ç•¥

        Args:
            documents: Document å¯¹è±¡åˆ—è¡¨

        Returns:
            å°å—åˆ—è¡¨ï¼Œæ¯ä¸ªå°å—çš„ metadata ä¸­åŒ…å«çˆ¶å—ä¿¡æ¯
        """
        # 1. åˆ›å»ºå¤§å—ï¼ˆçˆ¶å—ï¼‰
        big_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.big_chunk_size,
            chunk_overlap=self.big_chunk_overlap,
            add_start_index=True,
        )
        big_chunks = big_splitter.split_documents(documents)

        # 2. å¯¹æ¯ä¸ªå¤§å—å†åˆ†å‰²æˆå°å—
        small_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.small_chunk_size,
            chunk_overlap=self.small_chunk_overlap,
            add_start_index=True,
        )

        all_small_chunks = []
        for big_chunk_id, big_chunk in enumerate(big_chunks):
            # åˆ†å‰²æˆå°å—
            small_chunks = small_splitter.split_documents([big_chunk])

            # ä¸ºæ¯ä¸ªå°å—æ·»åŠ çˆ¶å—ä¿¡æ¯
            for small_chunk_id, small_chunk in enumerate(small_chunks):
                small_chunk.metadata.update({
                    "chunk_id": f"{big_chunk_id}_{small_chunk_id}",
                    "parent_chunk_id": big_chunk_id,
                    "parent_chunk_content": big_chunk.page_content,  # ä¿å­˜çˆ¶å—å†…å®¹
                    "chunk_size": len(small_chunk.page_content),
                    "parent_chunk_size": len(big_chunk.page_content),
                    "splitter_type": "small_to_big",
                    "is_small_chunk": True,  # æ ‡è®°è¿™æ˜¯å°å—
                })
                all_small_chunks.append(small_chunk)

        print(f"ğŸ“Š Small-to-Big ç­–ç•¥ï¼šç”Ÿæˆ {len(big_chunks)} ä¸ªçˆ¶å—ï¼Œ{len(all_small_chunks)} ä¸ªå­å—")
        return all_small_chunks


class StructureAwareSplitterOperator(SplitterOperator):
    """
    ç»“æ„æ„ŸçŸ¥åˆ†å—å™¨
    æ ¹æ®æ–‡æ¡£ç»“æ„ï¼ˆæ ‡é¢˜ã€æ®µè½ç­‰ï¼‰è¿›è¡Œåˆ†å—
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.chunk_size = self.config.get("chunk_size", 1000)
        self.chunk_overlap = self.config.get("chunk_overlap", 100)
        # ä¼˜å…ˆæ ¹æ®æ–‡æ¡£ç»“æ„åˆ†å‰²
        self.separators = [
            "\n# ",      # Markdown ä¸€çº§æ ‡é¢˜
            "\n## ",     # Markdown äºŒçº§æ ‡é¢˜
            "\n### ",    # Markdown ä¸‰çº§æ ‡é¢˜
            "\n\n",      # æ®µè½
            "\n",        # è¡Œ
            "ã€‚",        # ä¸­æ–‡å¥å­
            ". ",        # è‹±æ–‡å¥å­
        ]

    def execute(self, documents: List[Document]) -> List[Document]:
        """
        åŸºäºæ–‡æ¡£ç»“æ„è¿›è¡Œåˆ†å—

        Args:
            documents: Document å¯¹è±¡åˆ—è¡¨

        Returns:
            åˆ†å—åçš„ Document å¯¹è±¡åˆ—è¡¨
        """
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            add_start_index=True,
            separators=self.separators,
        )

        splits = splitter.split_documents(documents)

        # å…ƒæ•°æ®å¢å¼ºï¼šå°è¯•è¯†åˆ«å—çš„ç±»å‹
        for i, split in enumerate(splits):
            split.metadata["chunk_id"] = i
            split.metadata["chunk_size"] = len(split.page_content)
            split.metadata["splitter_type"] = "structure_aware"

            # ç®€å•çš„ç»“æ„è¯†åˆ«
            content = split.page_content.strip()
            if content.startswith("# "):
                split.metadata["chunk_type"] = "heading_1"
            elif content.startswith("## "):
                split.metadata["chunk_type"] = "heading_2"
            elif content.startswith("### "):
                split.metadata["chunk_type"] = "heading_3"
            else:
                split.metadata["chunk_type"] = "paragraph"

        return splits
