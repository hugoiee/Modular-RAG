"""
Selection/Filtering Operatorsï¼ˆé€‰æ‹©/è¿‡æ»¤ï¼‰

è®ºæ–‡æ ¸å¿ƒæŠ€æœ¯ï¼š
- ç›´æ¥ç§»é™¤ä¸ç›¸å…³çš„æ–‡æ¡£å—
- è¿‡æ»¤å™ªéŸ³å’Œå†—ä½™ä¿¡æ¯
- ç¡®ä¿åªæœ‰é«˜è´¨é‡æ–‡æ¡£è¢«ä¼ é€’ç»™ LLM
"""

from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_qwq import ChatQwen
from .base import BasePostRetrievalOperator


class SelectionOperator(BasePostRetrievalOperator):
    """
    åŸºç¡€ Selection æ“ä½œå™¨

    åŠŸèƒ½ï¼š
    - åªä¿ç•™å‰ N ä¸ªæ–‡æ¡£
    - ç®€å•å¿«é€Ÿçš„è¿‡æ»¤ç­–ç•¥

    åº”ç”¨åœºæ™¯ï¼š
    - å¿«é€Ÿé™åˆ¶æ–‡æ¡£æ•°é‡
    - å‡å°‘ LLM ä¸Šä¸‹æ–‡è´Ÿæ‹…
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.top_k = self.config.get("top_k", 5)

    def process(self, documents: List[Document], query: str = None) -> List[Document]:
        """
        é€‰æ‹©å‰ K ä¸ªæ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            é€‰æ‹©åçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []

        print(f"âœ‚ï¸  Selection: é€‰æ‹©å‰ {self.top_k} ä¸ªæ–‡æ¡£...")

        selected = documents[:self.top_k]

        print(f"   âœ“ ä» {len(documents)} ä¸ªæ–‡æ¡£ä¸­é€‰æ‹©äº† {len(selected)} ä¸ª")

        return selected


class RelevanceFilterOperator(BasePostRetrievalOperator):
    """
    Relevance Filter æ“ä½œå™¨ï¼ˆç›¸å…³æ€§è¿‡æ»¤ï¼‰

    åŠŸèƒ½ï¼š
    - ä½¿ç”¨ LLM åˆ¤æ–­æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§
    - ç§»é™¤ä¸ç›¸å…³çš„æ–‡æ¡£
    - æé«˜æ–‡æ¡£è´¨é‡

    åº”ç”¨åœºæ™¯ï¼š
    - éœ€è¦ç²¾ç¡®è¿‡æ»¤
    - å¯¹è´¨é‡è¦æ±‚é«˜
    - é¿å…è¯¯å¯¼ä¿¡æ¯
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.model = self.config.get("model", "qwen-plus")
        self.temperature = self.config.get("temperature", 0.0)
        self.relevance_threshold = self.config.get("relevance_threshold", 0.5)
        self.min_docs = self.config.get("min_docs", 1)

        # åˆå§‹åŒ– LLM
        self.llm = ChatQwen(
            model=self.model,
            temperature=self.temperature,
        )

    def process(self, documents: List[Document], query: str = None) -> List[Document]:
        """
        åŸºäºç›¸å…³æ€§è¿‡æ»¤æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢ï¼ˆå¿…éœ€ï¼‰

        Returns:
            è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []

        if not query:
            print("âš ï¸  Relevance Filter éœ€è¦æŸ¥è¯¢ï¼Œè¿”å›æ‰€æœ‰æ–‡æ¡£")
            return documents

        print(f"ğŸ¯ Relevance Filter: è¿‡æ»¤ {len(documents)} ä¸ªæ–‡æ¡£ï¼ˆé˜ˆå€¼: {self.relevance_threshold}ï¼‰...")

        filtered_docs = []

        for i, doc in enumerate(documents, 1):
            is_relevant = self._check_relevance(doc, query)

            if is_relevant:
                filtered_docs.append(doc)
                print(f"   âœ“ æ–‡æ¡£ {i}: ç›¸å…³")
            else:
                print(f"   âœ— æ–‡æ¡£ {i}: ä¸ç›¸å…³ï¼ˆå·²è¿‡æ»¤ï¼‰")

        # ç¡®ä¿è‡³å°‘ä¿ç•™ min_docs ä¸ªæ–‡æ¡£
        if len(filtered_docs) < self.min_docs and len(documents) > 0:
            print(f"   âš ï¸  è¿‡æ»¤ç»“æœå°‘äº {self.min_docs} ä¸ªï¼Œä¿ç•™å‰ {self.min_docs} ä¸ª")
            filtered_docs = documents[:self.min_docs]

        print(f"   âœ“ è¿‡æ»¤å®Œæˆï¼Œä¿ç•™ {len(filtered_docs)}/{len(documents)} ä¸ªæ–‡æ¡£")

        return filtered_docs

    def _check_relevance(self, doc: Document, query: str) -> bool:
        """
        æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³

        Args:
            doc: æ–‡æ¡£
            query: æŸ¥è¯¢

        Returns:
            æ˜¯å¦ç›¸å…³
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§åˆ¤æ–­ä¸“å®¶ã€‚åˆ¤æ–­æ–‡æ¡£æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
- ç›¸å…³ï¼šæ–‡æ¡£åŒ…å«æŸ¥è¯¢æ‰€éœ€çš„ä¿¡æ¯ï¼Œèƒ½å¸®åŠ©å›ç­”é—®é¢˜
- ä¸ç›¸å…³ï¼šæ–‡æ¡£å†…å®¹ä¸æŸ¥è¯¢ä¸»é¢˜æ— å…³ï¼Œä¸èƒ½æä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯

åªè¾“å‡º"ç›¸å…³"æˆ–"ä¸ç›¸å…³"ï¼Œä¸éœ€è¦è§£é‡Šã€‚"""),
            ("human", "æŸ¥è¯¢ï¼š{query}\n\næ–‡æ¡£ï¼š{document}\n\nåˆ¤æ–­ï¼š"),
        ])

        chain = prompt | self.llm | StrOutputParser()

        try:
            result = chain.invoke({
                "query": query,
                "document": doc.page_content[:500]  # åªä½¿ç”¨å‰500å­—ç¬¦
            }).strip()

            return "ç›¸å…³" in result or "relevant" in result.lower()
        except Exception as e:
            print(f"   âš ï¸  åˆ¤æ–­å¤±è´¥: {e}ï¼Œé»˜è®¤ä¿ç•™")
            return True


class RedundancyFilterOperator(BasePostRetrievalOperator):
    """
    Redundancy Filter æ“ä½œå™¨ï¼ˆå†—ä½™è¿‡æ»¤ï¼‰

    åŠŸèƒ½ï¼š
    - æ£€æµ‹å¹¶ç§»é™¤é‡å¤æˆ–é«˜åº¦ç›¸ä¼¼çš„æ–‡æ¡£
    - å‡å°‘å†—ä½™ä¿¡æ¯
    - æé«˜ä¿¡æ¯å¤šæ ·æ€§

    åº”ç”¨åœºæ™¯ï¼š
    - å»é™¤é‡å¤å†…å®¹
    - ä¼˜åŒ–ä¸Šä¸‹æ–‡åˆ©ç”¨ç‡
    - æä¾›å¤šæ ·åŒ–ä¿¡æ¯
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.similarity_threshold = self.config.get("similarity_threshold", 0.85)

    def process(self, documents: List[Document], query: str = None) -> List[Document]:
        """
        è¿‡æ»¤å†—ä½™æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            å»é‡åçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []

        print(f"ğŸ” Redundancy Filter: æ£€æµ‹å†—ä½™æ–‡æ¡£ï¼ˆé˜ˆå€¼: {self.similarity_threshold}ï¼‰...")

        filtered_docs = []
        filtered_docs.append(documents[0])  # ä¿ç•™ç¬¬ä¸€ä¸ª

        for i, doc in enumerate(documents[1:], 2):
            # æ£€æŸ¥ä¸å·²é€‰æ‹©æ–‡æ¡£çš„ç›¸ä¼¼åº¦
            is_redundant = False

            for selected_doc in filtered_docs:
                similarity = self._calculate_similarity(
                    doc.page_content,
                    selected_doc.page_content
                )

                if similarity >= self.similarity_threshold:
                    is_redundant = True
                    print(f"   âœ— æ–‡æ¡£ {i}: å†—ä½™ï¼ˆç›¸ä¼¼åº¦: {similarity:.2f}ï¼‰")
                    break

            if not is_redundant:
                filtered_docs.append(doc)
                print(f"   âœ“ æ–‡æ¡£ {i}: ä¿ç•™")

        print(f"   âœ“ å†—ä½™è¿‡æ»¤å®Œæˆï¼Œä¿ç•™ {len(filtered_docs)}/{len(documents)} ä¸ªæ–‡æ¡£")

        return filtered_docs

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€å•çš„è¯é‡å ï¼‰

        Args:
            text1: æ–‡æœ¬1
            text2: æ–‡æœ¬2

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        """
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = len(words1 & words2)
        union = len(words1 | words2)

        return intersection / union if union > 0 else 0.0


class QualityFilterOperator(BasePostRetrievalOperator):
    """
    Quality Filter æ“ä½œå™¨ï¼ˆè´¨é‡è¿‡æ»¤ï¼‰

    åŠŸèƒ½ï¼š
    - è¯„ä¼°æ–‡æ¡£è´¨é‡
    - ç§»é™¤ä½è´¨é‡æ–‡æ¡£
    - ç¡®ä¿ä¿¡æ¯å¯é æ€§

    è´¨é‡æ ‡å‡†ï¼š
    - æ–‡æ¡£é•¿åº¦åˆç†
    - åŒ…å«å®Œæ•´ä¿¡æ¯
    - è¯­è¨€è§„èŒƒ
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.min_length = self.config.get("min_length", 50)
        self.max_length = self.config.get("max_length", 5000)

    def process(self, documents: List[Document], query: str = None) -> List[Document]:
        """
        åŸºäºè´¨é‡è¿‡æ»¤æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            é«˜è´¨é‡æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []

        print(f"â­ Quality Filter: è¿‡æ»¤ä½è´¨é‡æ–‡æ¡£...")

        filtered_docs = []

        for i, doc in enumerate(documents, 1):
            quality_score = self._assess_quality(doc)

            if quality_score >= 0.5:  # è´¨é‡é˜ˆå€¼
                filtered_docs.append(doc)
                print(f"   âœ“ æ–‡æ¡£ {i}: è´¨é‡è‰¯å¥½ï¼ˆ{quality_score:.2f}ï¼‰")
            else:
                print(f"   âœ— æ–‡æ¡£ {i}: è´¨é‡ä¸ä½³ï¼ˆ{quality_score:.2f}ï¼‰")

        print(f"   âœ“ è´¨é‡è¿‡æ»¤å®Œæˆï¼Œä¿ç•™ {len(filtered_docs)}/{len(documents)} ä¸ªæ–‡æ¡£")

        return filtered_docs

    def _assess_quality(self, doc: Document) -> float:
        """
        è¯„ä¼°æ–‡æ¡£è´¨é‡

        Args:
            doc: æ–‡æ¡£

        Returns:
            è´¨é‡åˆ†æ•°ï¼ˆ0-1ï¼‰
        """
        content = doc.page_content
        score = 0.0

        # 1. é•¿åº¦æ£€æŸ¥ï¼ˆ30åˆ†ï¼‰
        length = len(content)
        if self.min_length <= length <= self.max_length:
            score += 0.3
        elif length < self.min_length:
            score += 0.1  # å¤ªçŸ­æ‰£åˆ†
        else:
            score += 0.2  # å¤ªé•¿ä¹Ÿæ‰£åˆ†

        # 2. å®Œæ•´æ€§æ£€æŸ¥ï¼ˆ30åˆ†ï¼‰
        # ç®€å•å¯å‘å¼ï¼šåŒ…å«æ ‡ç‚¹ç¬¦å·å’Œå®Œæ•´å¥å­
        has_periods = 'ã€‚' in content or '.' in content
        has_multiple_sentences = content.count('ã€‚') > 1 or content.count('.') > 1

        if has_periods and has_multiple_sentences:
            score += 0.3
        elif has_periods:
            score += 0.15

        # 3. ä¿¡æ¯å¯†åº¦æ£€æŸ¥ï¼ˆ20åˆ†ï¼‰
        # è¯æ±‡å¤šæ ·æ€§
        words = content.split()
        unique_words = set(words)
        diversity = len(unique_words) / len(words) if words else 0

        if diversity > 0.5:
            score += 0.2
        elif diversity > 0.3:
            score += 0.1

        # 4. æ ¼å¼æ£€æŸ¥ï¼ˆ20åˆ†ï¼‰
        # é¿å…è¿‡å¤šç‰¹æ®Šå­—ç¬¦æˆ–é‡å¤
        special_char_ratio = sum(1 for c in content if not c.isalnum() and c not in 'ã€‚ï¼Œï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€Šã€‹\n ') / len(content) if content else 0

        if special_char_ratio < 0.1:
            score += 0.2
        elif special_char_ratio < 0.2:
            score += 0.1

        return min(score, 1.0)


class ContradictionFilterOperator(BasePostRetrievalOperator):
    """
    Contradiction Filter æ“ä½œå™¨ï¼ˆçŸ›ç›¾è¿‡æ»¤ï¼‰

    åŠŸèƒ½ï¼š
    - æ£€æµ‹æ–‡æ¡£é—´çš„çŸ›ç›¾ä¿¡æ¯
    - ç§»é™¤çŸ›ç›¾æˆ–å†²çªçš„æ–‡æ¡£
    - æé«˜ä¿¡æ¯ä¸€è‡´æ€§

    åº”ç”¨åœºæ™¯ï¼š
    - äº‹å®æ€§æŸ¥è¯¢
    - éœ€è¦ä¸€è‡´æ€§çš„åœºæ™¯
    - é¿å…è¯¯å¯¼ä¿¡æ¯
    """

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.model = self.config.get("model", "qwen-plus")
        self.temperature = self.config.get("temperature", 0.0)

        # åˆå§‹åŒ– LLM
        self.llm = ChatQwen(
            model=self.model,
            temperature=self.temperature,
        )

    def process(self, documents: List[Document], query: str = None) -> List[Document]:
        """
        è¿‡æ»¤çŸ›ç›¾æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            æ— çŸ›ç›¾çš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents or len(documents) < 2:
            return documents

        print(f"âš–ï¸  Contradiction Filter: æ£€æµ‹çŸ›ç›¾æ–‡æ¡£...")

        # ä¿ç•™ç¬¬ä¸€ä¸ªæ–‡æ¡£ä½œä¸ºåŸºå‡†
        filtered_docs = [documents[0]]

        for i, doc in enumerate(documents[1:], 2):
            # æ£€æŸ¥ä¸å·²é€‰æ‹©æ–‡æ¡£æ˜¯å¦çŸ›ç›¾
            has_contradiction = self._check_contradiction(doc, filtered_docs)

            if not has_contradiction:
                filtered_docs.append(doc)
                print(f"   âœ“ æ–‡æ¡£ {i}: æ— çŸ›ç›¾")
            else:
                print(f"   âœ— æ–‡æ¡£ {i}: å­˜åœ¨çŸ›ç›¾ï¼ˆå·²è¿‡æ»¤ï¼‰")

        print(f"   âœ“ çŸ›ç›¾æ£€æµ‹å®Œæˆï¼Œä¿ç•™ {len(filtered_docs)}/{len(documents)} ä¸ªæ–‡æ¡£")

        return filtered_docs

    def _check_contradiction(self, doc: Document, reference_docs: List[Document]) -> bool:
        """
        æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸å‚è€ƒæ–‡æ¡£çŸ›ç›¾

        Args:
            doc: å¾…æ£€æŸ¥æ–‡æ¡£
            reference_docs: å‚è€ƒæ–‡æ¡£åˆ—è¡¨

        Returns:
            æ˜¯å¦å­˜åœ¨çŸ›ç›¾
        """
        # ç®€åŒ–ç‰ˆï¼šåªæ£€æŸ¥ä¸ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„çŸ›ç›¾
        if not reference_docs:
            return False

        reference_content = reference_docs[0].page_content[:300]
        doc_content = doc.page_content[:300]

        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªäº‹å®ä¸€è‡´æ€§æ£€æŸ¥ä¸“å®¶ã€‚åˆ¤æ–­ä¸¤æ®µæ–‡æœ¬æ˜¯å¦å­˜åœ¨äº‹å®çŸ›ç›¾ã€‚

çŸ›ç›¾çš„å®šä¹‰ï¼š
- ä¸¤æ®µæ–‡æœ¬å¯¹åŒä¸€äº‹å®ç»™å‡ºäº†ä¸åŒçš„æè¿°
- æ•°å­—ã€æ—¥æœŸã€äººåç­‰å…³é”®ä¿¡æ¯å†²çª
- ç»“è®ºæˆ–è§‚ç‚¹å®Œå…¨ç›¸å

åªè¾“å‡º"çŸ›ç›¾"æˆ–"æ— çŸ›ç›¾"ï¼Œä¸éœ€è¦è§£é‡Šã€‚"""),
            ("human", "æ–‡æœ¬1ï¼š{text1}\n\næ–‡æœ¬2ï¼š{text2}\n\nåˆ¤æ–­ï¼š"),
        ])

        chain = prompt | self.llm | StrOutputParser()

        try:
            result = chain.invoke({
                "text1": reference_content,
                "text2": doc_content
            }).strip()

            return "çŸ›ç›¾" in result or "contradiction" in result.lower()
        except Exception as e:
            print(f"   âš ï¸  çŸ›ç›¾æ£€æµ‹å¤±è´¥: {e}ï¼Œé»˜è®¤ä¿ç•™")
            return False
